import numpy as np
import matplotlib.pyplot as plt
train_loss=[0.15806005507115486, 0.058863684767857194, 0.05561045217919021, 0.054130585351915714, 0.0532178052205185, 0.05244570851314768, 0.05192204255419088, 0.05150504988912524, 0.051005027839090535, 0.05076012576294094, 0.05052069752831858, 0.05028420414445892, 0.050109786123893565, 0.04993403666247929, 0.04979200782496016, 0.04964249676777062, 0.04957086822290778, 0.04940693428657045, 0.049225987994049064, 0.04907798520039052, 0.04897391472781721, 0.048672807400319394, 0.048560558249474785, 0.04837524446622538, 0.04818429651025396, 0.04803196753118881, 0.04770437978873542, 0.047416286581852735, 0.047371105440919034, 0.04724471715541748, 0.04703277179952348, 0.04699157516232953, 0.046787047234451894, 0.04662756009400236, 0.046522378972649533, 0.04640336693650797, 0.046387849273971445, 0.04619274417627206, 0.046035424697638404, 0.04599079938300741, 0.045876681302420355, 0.04586325845235753, 0.045751557128065445, 0.04573128925894488, 0.04551458363004799, 0.04549202877545662, 0.04548074356672994, 0.04534564202174931, 0.04523502705503079, 0.0453064969043395, 0.0451387607892138, 0.04512041489433142, 0.045096798811152757, 0.04509465214692788, 0.04492378919847151, 0.04488136798300477, 0.04482197281675788, 0.04483403315948041, 0.04484672726030989, 0.0446667440185553, 0.04482120767678544, 0.044638467325541546, 0.04466757830771841, 0.044517788909802056, 0.04452567815358135, 0.044577669772531824, 0.044293213622520256, 0.04450341256139446, 0.0443752578216276, 0.04427711845248716, 0.044318685042469025, 0.04434525940793396, 0.04415903746023553, 0.04424428129810374, 0.04412925828798942, 0.04416998528462832, 0.044106994390028485, 0.04399013253484712, 0.04404341515440207, 0.04396642164773445, 0.04400540383116612, 0.04387890502156222, 0.04387133994978698, 0.043948113418980896, 0.043852144330947126, 0.043847073724042826, 0.043827869096232284, 0.04368011386283053, 0.04371897195464999, 0.04377326731111741, 0.04365930115446738, 0.043559070429061236, 0.043531983558682374, 0.043604836748710955, 0.04366123459307931, 0.0435571525719766, 0.04357345117924112, 0.043468184442672815, 0.043499794124044734, 0.04343399979895718, 0.04338885733315702, 0.043365391765171325, 0.04337293313224079, 0.04342473689947913, 0.04339229712798756, 0.04324038664134309, 0.04332870786057559, 0.043201251542825767, 0.043237518478164226, 0.04323780722937705, 0.043140739506970234, 0.04321230439671192, 0.04325463567977811, 0.04320690647146101, 0.04321724912747257, 0.0430816165445609, 0.043150802637278635, 0.043055128228036726, 0.043038985612556216, 0.04300817487950405, 0.042985838051713604, 0.043221922650021796, 0.04284451456189819, 0.043018857198633575, 0.04291066687057387, 0.04287287729058201, 0.042908018679432294, 0.04282618378870797, 0.04295140734020935, 0.04288217428086828, 0.04275501827106046, 0.042829397190155064, 0.042828122746204546, 0.042783677743478535, 0.04258396894091859, 0.042731656371620144, 0.04272977579667719, 0.04274494123953266, 0.04267931372044648, 0.04275358007078001, 0.04265698360191163, 0.04259130098083185, 0.04256208992927431, 0.04260073603796354, 0.042618843060473637, 0.04253154174438518, 0.04250619126862714, 0.04239496155413242, 0.04255624443814383, 0.04252436495859925, 0.04251675618781369, 0.04255988031090172, 0.042419922148180474, 0.04245931508899532, 0.04248714738092157, 0.04237363597725978, 0.042340424086810526, 0.042383567692472, 0.04241011958794567, 0.04223538757745518, 0.04227311825819928, 0.042267417276029555, 0.042346640222207875, 0.0423789644405415, 0.042281678400025724, 0.04220177800622462, 0.042183908304601794, 0.04224598566864283, 0.04220394048998624, 0.042129483959742024, 0.042168156750305136, 0.04208667757269254, 0.0421851447440746, 0.04208288403517939, 0.042094508073667276, 0.04209082812611169, 0.04197907637790937, 0.04199590906910806, 0.04204425744110748, 0.0419884171396014, 0.041966325568900106, 0.04196398972298007, 0.04199750470929711, 0.041965014844152305, 0.04194506588309962, 0.04191464761209927, 0.04184818168475437, 0.04188096140516944, 0.0419224075199665, 0.04190130039952018, 0.04172523493988162, 0.04184722421199698, 0.041692091376055465, 0.041713949400358476, 0.04167866834203701, 0.04177222386068571, 0.04169815553195146, 0.04171064097962521, 0.04167526457985247, 0.04164712018697187, 0.041704690303960755]
valid_loss=[0.06568892617341832, 0.0602186968566178, 0.05856606277252988, 0.058494833553990364, 0.05693598804979326, 0.05593776781128047, 0.0556044627471825, 0.05457872588119065, 0.05438226010835454, 0.054132294015391665, 0.05437394907621598, 0.054291571254115836, 0.05377206812083689, 0.05345961159260111, 0.053878109937344654, 0.053741581318095394, 0.05328098862566714, 0.05375868266550965, 0.05302291037313656, 0.0528476353242921, 0.0527660178732666, 0.0526646081487433, 0.05220099071797072, 0.05198497289528197, 0.05212190498489299, 0.051432916105042976, 0.052195306811039184, 0.05174445621085959, 0.0508395813528215, 0.050917464862607786, 0.05116390055658992, 0.051054495888144646, 0.050752537364751646, 0.05041825453314295, 0.050087335813673896, 0.05088004002299313, 0.05030744115984948, 0.05077965096892391, 0.05011874489228746, 0.0500056489499499, 0.04991304914549508, 0.0497265226840289, 0.051515139318544005, 0.05045770620977502, 0.0494263316876784, 0.049775396723131256, 0.05027286937564901, 0.05079055006553461, 0.049474566510615, 0.04948532907644258, 0.04983296241313541, 0.05008045758410371, 0.04941677142761358, 0.050218644282392366, 0.04984952051184476, 0.049466883460940796, 0.0509454343989934, 0.050519725229876765, 0.04956647977293278, 0.0494998747414505, 0.049419787319650625, 0.049342929065774636, 0.04923127121925676, 0.05046358889171986, 0.049312139371989326, 0.04952617828758357, 0.049151984558613734, 0.04952924576694584, 0.05025096192803097, 0.04932866820142268, 0.0489273439131307, 0.04981345183429254, 0.04900745264471752, 0.049415189414798055, 0.049007717429481235, 0.049467711405703885, 0.05033108637292043, 0.05017249006979151, 0.050098425571175116, 0.04925204967661533, 0.04949166374401739, 0.04947594217689543, 0.0501160050695058, 0.0496658713377803, 0.049335050718963436, 0.049281790989831285, 0.049441419916979756, 0.04930573045431996, 0.04915300546340709, 0.049635144331760014, 0.04984692405138897, 0.04973364025897489, 0.049397311923164496, 0.04917083395097895, 0.04950308554994896, 0.04895102469548261, 0.04908975533644224, 0.0493164990242112, 0.04961158750482209, 0.04914776505610743, 0.05012557860946617, 0.04948421361902427, 0.049168346480910965, 0.04916192662548153, 0.048754094110210436, 0.048753014724947044, 0.04902273589809532, 0.049068069331887024, 0.04907596464516277, 0.0489532338177733, 0.048848892261875596, 0.04928318265378958, 0.048693997213178464, 0.04917442201401387, 0.04912157023484471, 0.049109724114928595, 0.04924174721380917, 0.04910897728524394, 0.049232753184794996, 0.0490789846336111, 0.04892252079718072, 0.04910336632772347, 0.05001217601609619, 0.04999938813545067, 0.04936096127513096, 0.04894014220276433, 0.04896730985331548, 0.048957251358805444, 0.05010513618656839, 0.050029159348546556, 0.04907931403315286, 0.04891397945404849, 0.04932477019755391, 0.04900475855807112, 0.05033026908204507, 0.048838323034490934, 0.049062748466262324, 0.04921583195426149, 0.049003530329910006, 0.04882736886010684, 0.04909309556558889, 0.049492332783123365, 0.04907077473847771, 0.04913026183897923, 0.049343279245325625, 0.04952658966714697, 0.04883203810668243, 0.04964450028771233, 0.04902151631358327, 0.04939075342035545, 0.049445626166494276, 0.04985110483536614, 0.04906923851485064, 0.04898691545773627, 0.0491831878026179, 0.04943667640949782, 0.04933517493134602, 0.04911439762838973, 0.04925596628933501, 0.04905226483506595, 0.04934564684507624, 0.04986077864889707, 0.050230308708917856, 0.04906339576361263, 0.04901218215369702, 0.04926500959144845, 0.04932356567763709, 0.049405950732573416, 0.04924438997135612, 0.04926969142571357, 0.04946217247834087, 0.04951554305899735, 0.04953927986653719, 0.04943405390017089, 0.04936666593919096, 0.0496421750478012, 0.04942379748151028, 0.04966640583346105, 0.049082984494097676, 0.04956396905600735, 0.04910179983611273, 0.0494863254452611, 0.0491669661331254, 0.04976228811450254, 0.050129268508501044, 0.049005525744848004, 0.050261468054288216, 0.049425754617682414, 0.04943457189404263, 0.04905398740869651, 0.04944121511351341, 0.049617310902445734, 0.049723138230134675, 0.05010412880782738, 0.04979135066655024, 0.04942065047313405, 0.04956279516614346, 0.05011299645656933, 0.04993849153656585, 0.04962247332279444, 0.05067654689029664]

plt.plot(train_loss, label='train_loss')
plt.plot(valid_loss, label='valid_loss')
plt.xlabel('step')
plt.ylabel('loss')
plt.legend()
plt.show()